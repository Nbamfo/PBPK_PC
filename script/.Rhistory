true_sd <- sqrt(1/(beta2_full[1] + beta2_full[2]*x_val + beta2_full[3]*x_val^2))
num_trial <- 600
Ysim <- matrix(0,n,0)
glm_pred <- matrix(0,num_trial,0)
glm_sd <- matrix(0,num_trial,0)
lm_pred <- matrix(0,num_trial,0)
lm_sd <- matrix(0,num_trial,0)
glm_std_error <- matrix(0,num_trial,0)
glm_std_error_sd <- matrix(0,num_trial,0)
lm_std_error <- matrix(0,num_trial,0)
lm_std_error_sd <- matrix(0,num_trial,0)
glm_con_int_count <- matrix(0,num_trial,2)
lm_con_int_count <- matrix(0,num_trial,2)
for (M in 1:num_trial){
# Simulate new yi values
Ysim <- rnorm(50, eta1_true/eta2_true, sqrt(1/eta2_true))
# Fit and predict with the GLM
beta1 <- fit_full$coefficients/var_est
names(beta1) <- c("beta10", "beta11", "beta12")
beta2 <- c(1/var_est, 0, 0)
names(beta2) <- c("beta20","beta21","beta22")
X1 <- cbind(matrix(1,n,1),x,x^2)
X2 <- cbind(matrix(1,n,1),x,x^2)
# Run the Newton-Raphson optimization method
beta_all_new <- newton_raphson(beta1,beta2,Ysim,X1,X2)
beta1_new <- beta_all_new[,1]
beta2_new <- beta_all_new[,2]
# Calculate the GLM predicted value and standard deviation
glm_pred[M] <- (beta1_new[1] + beta1_new[2]*x_val + beta1_new[3]*x_val^2)/
(beta2_new[1] + beta2_new[2]*x_val + beta2_new[3]*x_val^2)
glm_sd[M] <- sqrt(1/(beta2_new[1] + beta2_new[2]*x_val + beta2_new[3]*x_val^2))
# Calculate the standard error at x_val
grad_glm <- c(1/(beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2),
x_val/(beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2),
x_val^2/(beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2),
-(beta1_new[1]+beta1_new[2]*x_val+beta1_new[3]*x_val^2)/
((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^2),
-x_val*(beta1_new[1]+beta1_new[2]*x_val+beta1_new[3]*x_val^2)/
((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^2),
-x_val^2*(beta1_new[1]+beta1_new[2]*x_val+beta1_new[3]*x_val^2)/
((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^2))
Fisher_IM <- -D2lik(beta1_new,beta2_new,Ysim,X1,X2)
GLM_cov <- solve(Fisher_IM)
glm_std_error[M] <- sqrt(t(grad_glm)%*%GLM_cov%*%grad_glm)
# Find prediction CI and check if true_value falls within it
glm_con_int <- c(glm_pred[M] + qnorm(0.975)*glm_std_error[M],
glm_pred[M] - qnorm(0.975)*glm_std_error[M])
if (true_value <= max(glm_con_int) && true_value >=min(glm_con_int)){
glm_con_int_count[M,1] <- 1
}else{
glm_con_int_count[M,1] <- 0
}
# Find std deviation CI and check if true_sd falls within it
grad_glm_sd <- c(0, 0, 0,
-(1/2)*((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^(-3/2)),
-(1/2)*x_val*((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^(-3/2)),
-(1/2)*x_val^2*((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^(-3/2)))
Fisher_IM_sd <- -D2lik(beta1_new,beta2_new,Ysim,X1,X2)
GLM_cov_sd <- solve(Fisher_IM_sd)
glm_std_error_sd[M] <- sqrt(t(grad_glm_sd)%*%GLM_cov_sd%*%grad_glm_sd)
glm_con_int_sd <- c(glm_sd[M] + qnorm(0.975)*glm_std_error_sd[M],
glm_sd[M] - qnorm(0.975)*glm_std_error_sd[M])
if (true_sd <= max(glm_con_int_sd) && true_sd >=min(glm_con_int_sd)){
glm_con_int_count[M,2] <- 1
}else{
glm_con_int_count[M,2] <- 0
}
#-----------------------------------------------
# Fit and predict with the standard linear model
fit_lm <- lm(Ysim~x+x2)
lm_pred[M] <- fit_lm$coefficients[1] + fit_lm$coefficients[2]*x_val +
fit_lm$coefficients[3]*x_val^2
# Find standard deviation
lm_sd[M] <- sqrt(sum(fit_lm$residuals^2)/n)
# Find standard error for prediction
var_est_lm <- sum(fit_lm$residuals^2)/n # variance estimator
beta1_lm <- fit_full$coefficients/var_est
names(beta1_lm) <- c("beta10", "beta11", "beta12")
beta2_lm <- 1/var_est
names(beta2_lm) <- c("beta20")
X1 <- cbind(matrix(1,n,1),x,x^2)
X2_lm <- cbind(matrix(1,n,1))
grad_lm <- c(1/beta2_lm[1], x_val/beta2_lm[1], x_val^2/beta2_lm[1],
(-beta1_lm[1]-beta1_lm[2]*x_val-beta1_lm[3]*x_val^2)/beta2_lm[1]^2)
Fisher_IM <- -D2lik(beta1_lm,beta2_lm,Ysim,X1,X2_lm)
LM_cov <- solve(Fisher_IM)
lm_std_error[M] <- sqrt(t(grad_lm)%*%LM_cov%*%grad_lm)
lm_con_int <- c(lm_pred[M] + qnorm(0.975)*lm_std_error[M],
lm_pred[M] - qnorm(0.975)*lm_std_error[M])
if (true_value <= max(lm_con_int) && true_value >=min(lm_con_int)){
lm_con_int_count[M,1] <- 1
}else{
lm_con_int_count[M,1] <- 0
}
# Find std deviation CI and check if true_sd falls within it
grad_lm_sd <- c(0,0,0,-0.5*beta2_lm^(-3/2))
Fisher_IM_sd <- -D2lik(beta1_lm,beta2_lm,Ysim,X1,X2_lm)
LM_cov_sd <- solve(Fisher_IM_sd)
lm_std_error_sd[M] <- sqrt(t(grad_lm_sd)%*%LM_cov_sd%*%grad_lm_sd)
lm_con_int_sd <- c(lm_sd[M] + qnorm(0.975)*lm_std_error_sd[M],
lm_sd[M] - qnorm(0.975)*lm_std_error_sd[M])
if (true_sd <= max(lm_con_int_sd) && true_sd >=min(lm_con_int_sd)){
lm_con_int_count[M,2] <- 1
}else{
lm_con_int_count[M,2] <- 0
}
}
M
glm_pred[M]
knitr::opts_chunk$set(echo = TRUE)
#clear environment
rm(list=ls())
load("Normal_GLM.Rdata")
source("Normal_GLM.r")
x2 <- x^2
fit_full <- lm(y~x+x2)
SSres_full <- sum(fit_full$residuals^2)
fit <- lm(y~x)
SSres <- sum(fit$residuals^2)
n <- length(y)
p <- 3
q <- 1
f_stat <- ((SSres - SSres_full)/SSres_full)*(n-p)/q
p_value <- 1-pf(f_stat,q,n-q)
p_value
hist(fit_full$residuals, xlab="Residuals", main="Histogram of residuals")
qqnorm(fit_full$residuals)
qqline(fit_full$residuals)
# Estimate the variance
var_est <- sum(fit_full$residuals^2)/n
beta1 <- fit_full$coefficients/var_est
names(beta1) <- c("beta10", "beta11", "beta12")
beta2 <- 1/var_est
names(beta2) <- c("beta20")
X1 <- cbind(matrix(1,n,1),x,x^2)
X2 <- cbind(matrix(1,n,1))
log_lik <- lik(beta1,beta2,y,X1,X2)
log_lik
grad <- Dlik(beta1,beta2,y,X1,X2)
grad
newton_raphson <- function(beta1,beat2,y,X1,X2){
baseline <- lik(beta1,beta2,y,X1,X2)
gradient_temp <- Dlik(beta1,beta2,y,X1,X2)
matrix_temp <- D2lik(beta1,beta2,y,X1,X2)
grad_threshold <- 1e-5 # set threshold to approximate when gradient is zero
beta1_new <- beta1
beta2_new <- beta2
count <- 0
max_iteration <- 100
while (max(abs(gradient_temp)) > grad_threshold && count <= max_iteration){
gradient_temp <- Dlik(beta1_new,beta2_new,y,X1,X2)
matrix_temp <- D2lik(beta1_new,beta2_new,y,X1,X2)
hm <- -solve(matrix_temp)%*%gradient_temp
beta1_temp <- beta1_new + hm[1:length(beta1)]
beta2_temp <- beta2_new + hm[(length(beta1)+1):length(hm)]
eta2 <- X2%*%beta2_temp
# If eta2 < 0, divide hm by 2 until eta >= 0
while (min(eta2) < 0){
hm <- hm/2
beta1_temp <- beta1_new + hm[1:length(beta1)]
beta2_temp <- beta2_new + hm[(length(beta1)+1):length(hm)]
eta2 <- X2%*%beta2_temp
}
lik_new <- lik(beta1_temp,beta2_temp,y,X1,X2)
# If likelihood did not increase, divide hm by 2 until it does
while(lik_new <= baseline){
hm <- hm/2
beta1_temp <- beta1_new+ hm[1:length(beta1)]
beta2_temp <- beta2_new + hm[(length(beta1)+1):length(hm)]
lik_new <- lik(beta1_temp,beta2_temp,y,X1,X2)
}
baseline <- lik(beta1_temp,beta2_temp,y,X1,X2)
beta1_new <- beta1_temp
beta2_new <- beta2_temp
gradient_temp <- Dlik(beta1_new,beta2_new,y,X1,X2)
count <- count + 1
}
if (length(beta1_new) < length(beta2_new)){
beta1_new <- c(beta1_new, 0)
}else if (length(beta1_new) > length(beta2_new)){
beta2_new <- c(beta2_new, rep(0,(length(beta1_new)-length(beta2_new))))
}
return(cbind(beta1_new,beta2_new))
}
var_est <- sum(fit_full$residuals^2)/n # variance estimator
beta1 <- fit_full$coefficients/var_est
names(beta1) <- c("beta10", "beta11", "beta12")
beta2 <- c(1/var_est, 0, 0)
names(beta2) <- c("beta20","beta21","beta22")
X1 <- cbind(matrix(1,n,1),x,x^2)
X2 <- cbind(matrix(1,n,1),x,x^2)
# Apply the Newton-Raphson optimization and store the MLE of beta1 and beta2
beta_all <- newton_raphson(beta1,beta2,y,X1,X2)
beta1_full <- beta_all[,1]
beta2_full <- beta_all[,2]
# Calculate expected value for GLM
eta1 <- X1%*%beta1_full
eta2 <- X2%*%beta2_full
GLM_est <- eta1/eta2
# Calculate expected value for standard linear model
LM_est <- matrix(0,n,0)
for(j in 1:n){
LM_est[j] <- fit_full$coefficients[1] + fit_full$coefficients[2]*x[j]  +
fit_full$coefficients[3]*x[j]^2
}
# Plot data with estimated expectation from GLM and standard linear model
plot(x, y, ylim=c(0,15), ylab="y", pch=19)
par(new=TRUE)
plot(x, GLM_est, ylim=c(0,15), ylab="y", pch=17, col="red")
par(new=TRUE)
plot(x, LM_est, ylim=c(0,15), ylab="y", pch=18, col="blue")
legend("top",legend=c("Data","GLM","SLM"),pch=c(19,17,18),col=c("black","red","blue"))
# Plot of residuals of the GLM
# Calculate the residuals
GLM_res <- GLM_est - y
# Calculate the standard errors
glm_std_error <- matrix(0,n,0)
for (h in 1:n){
grad_glm <- c(1/(beta2_full[1]+beta2_full[2]*x[h]+beta2_full[3]*x[h]^2),
x[h]/(beta2_full[1]+beta2_full[2]*x[h]+beta2_full[3]*x[h]^2),
x[h]^2/(beta2_full[1]+beta2_full[2]*x[h]+beta2_full[3]*x[h]^2),
-(beta1_full[1]+beta1_full[2]*x[h]+beta1_full[3]*x[h]^2)/
((beta2_full[1]+beta2_full[2]*x[h]+beta2_full[3]*x[h]^2)^2),
-x[h]*(beta1_full[1]+beta1_full[2]*x[h]+beta1_full[3]*x[h]^2)/
((beta2_full[1]+beta2_full[2]*x[h]+beta2_full[3]*x[h]^2)^2),
-x[h]^2*(beta1_full[1]+beta1_full[2]*x[h]+beta1_full[3]*x[h]^2)/
((beta2_full[1]+beta2_full[2]*x[h]+beta2_full[3]*x[h]^2)^2))
Fisher_IM <- -D2lik(beta1_full,beta2_full,y,X1,X2)
GLM_cov <- solve(Fisher_IM)
glm_std_error[h] <- sqrt(t(grad_glm)%*%GLM_cov%*%grad_glm)
}
plot(x, GLM_res, ylim=c(-2,2), pch=19, cex=0.8, ylab="Residuals")
arrows(x, GLM_res-glm_std_error, x, GLM_res+glm_std_error,
length=0.02, angle=90, code=3)
# Plot of residuals for standard linear model
# Calculate standard error
lm_std_error <- matrix(0,n,0)
for (k in 1:n){
grad_lm <- c(1, x[k], x[k]^2)
var <- t(grad_lm)%*%vcov(fit_full)%*%grad_lm
lm_std_error[k] <- sqrt(var)
}
#----------------------------
# Another way to calculate standard error (does not use "vcov")
beta1 <- fit_full$coefficients/var_est
names(beta1) <- c("beta10", "beta11", "beta12")
beta2 <- 1/var_est
names(beta2) <- c("beta20")
X1 <- cbind(matrix(1,n,1),x,x^2)
X2_standard <- cbind(matrix(1,n,1))
lm_std_error2 <- matrix(0,n,0)
for (w in 1:n){
grad_lm2 <- c(1/beta2[1], x[w]/beta2[1], x[w]^2/beta2[1],
(-beta1[1]-beta1[2]*x[w]-beta1[3]*x[w]^2)/beta2[1]^2)
Fisher_IM <- -D2lik(beta1,beta2,y,X1,X2_standard)
LM_cov <- solve(Fisher_IM)
lm_std_error2[w] <- sqrt(t(grad_lm2)%*%LM_cov%*%grad_lm2)
}
#----------------------------
plot(x, fit_full$residuals, ylim=c(-3,5), pch=19, cex=0.8, ylab="Residuals")
arrows(x, fit_full$residuals-lm_std_error2, x, fit_full$residuals+lm_std_error2,
length=0.02, angle=90, code=3)
# Test significance of quadratic term in eta1
glm_dev_full <- -2*lik(beta1_full, beta2_full, y, X1, X2)
# Optimize the GLM with no quadratic term in eta1
var_est <- sum(fit_full$residuals^2)/n
beta1 <- fit_full$coefficients[1:2]/var_est
names(beta1) <- c("beta10", "beta11")
beta2 <- c(1/var_est, 0, 0)
names(beta2) <- c("beta20","beta21","beta22")
X1_red <- cbind(matrix(1,n,1),x)
X2 <- cbind(matrix(1,n,1),x,x^2)
beta_eta1 <- newton_raphson(beta1,beta2,y,X1_red,X2)
beta1_eta1 <- beta_eta1[1:2,1]
beta2_eta1 <- beta_eta1[,2]
glm_dev_eta1_red <- -2*lik(beta1_eta1, beta2_eta1, y, X1_red, X2)
1-pchisq(glm_dev_eta1_red - glm_dev_full, 1)
# Test significance of quadratic term in eta2
# Optimize the GLM with no quadratic term in eta2
var_est <- sum(fit_full$residuals^2)/n
beta1 <- fit_full$coefficients/var_est
names(beta1) <- c("beta10", "beta11", "beta12")
beta2 <- c(1/var_est, 0)
names(beta2) <- c("beta20","beta21")
X1 <- cbind(matrix(1,n,1),x,x^2)
X2_red <- cbind(matrix(1,n,1),x)
beta_eta2 <- newton_raphson(beta1,beta2,y,X1,X2_red)
beta1_eta2 <- beta_eta2[,1]
beta2_eta2 <- beta_eta2[1:2,2]
glm_dev_eta2_red <- -2*lik(beta1_eta2, beta2_eta2, y, X1, X2_red)
1-pchisq(glm_dev_eta2_red - glm_dev_full, 1)
# Test whether the normal GLM is a better model for this data than the standard normal model
# Optimize the GLM with no quadratic term in eta2
var_est <- sum(fit_full$residuals^2)/n
beta1 <- fit_full$coefficients/var_est
names(beta1) <- c("beta10", "beta11", "beta12")
beta2 <- c(1/var_est)
names(beta2) <- c("beta20")
X1 <- cbind(matrix(1,n,1),x,x^2)
X2_red2 <- cbind(matrix(1,n,1))
beta_sd <- newton_raphson(beta1,beta2,y,X1,X2_red2)
beta1_sd <- beta_sd[,1]
beta2_sd <- beta_sd[1,2]
glm_dev_std <- -2*lik(beta1_sd, beta2_sd, y, X1, X2_red2)
1-pchisq(glm_dev_std-glm_dev_full, 2)
eta1_true <- X1%*%beta1_full
eta2_true <- X2%*%beta2_full
x_val <- 0.75
true_value <- (beta1_full[1] + beta1_full[2]*x_val + beta1_full[3]*x_val^2)/
(beta2_full[1] + beta2_full[2]*x_val + beta2_full[3]*x_val^2)
true_sd <- sqrt(1/(beta2_full[1] + beta2_full[2]*x_val + beta2_full[3]*x_val^2))
num_trial <- 500
Ysim <- matrix(0,n,0)
glm_pred <- matrix(0,num_trial,0)
glm_sd <- matrix(0,num_trial,0)
lm_pred <- matrix(0,num_trial,0)
lm_sd <- matrix(0,num_trial,0)
glm_std_error <- matrix(0,num_trial,0)
glm_std_error_sd <- matrix(0,num_trial,0)
lm_std_error <- matrix(0,num_trial,0)
lm_std_error_sd <- matrix(0,num_trial,0)
glm_con_int_count <- matrix(0,num_trial,2)
lm_con_int_count <- matrix(0,num_trial,2)
for (M in 1:num_trial){
# Simulate new yi values
Ysim <- rnorm(50, eta1_true/eta2_true, sqrt(1/eta2_true))
# Fit and predict with the GLM
beta1 <- fit_full$coefficients/var_est
names(beta1) <- c("beta10", "beta11", "beta12")
beta2 <- c(1/var_est, 0, 0)
names(beta2) <- c("beta20","beta21","beta22")
X1 <- cbind(matrix(1,n,1),x,x^2)
X2 <- cbind(matrix(1,n,1),x,x^2)
# Run the Newton-Raphson optimization method
beta_all_new <- newton_raphson(beta1,beta2,Ysim,X1,X2)
beta1_new <- beta_all_new[,1]
beta2_new <- beta_all_new[,2]
# Calculate the GLM predicted value and standard deviation
glm_pred[M] <- (beta1_new[1] + beta1_new[2]*x_val + beta1_new[3]*x_val^2)/
(beta2_new[1] + beta2_new[2]*x_val + beta2_new[3]*x_val^2)
glm_sd[M] <- sqrt(1/(beta2_new[1] + beta2_new[2]*x_val + beta2_new[3]*x_val^2))
# Calculate the standard error at x_val
grad_glm <- c(1/(beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2),
x_val/(beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2),
x_val^2/(beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2),
-(beta1_new[1]+beta1_new[2]*x_val+beta1_new[3]*x_val^2)/
((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^2),
-x_val*(beta1_new[1]+beta1_new[2]*x_val+beta1_new[3]*x_val^2)/
((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^2),
-x_val^2*(beta1_new[1]+beta1_new[2]*x_val+beta1_new[3]*x_val^2)/
((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^2))
Fisher_IM <- -D2lik(beta1_new,beta2_new,Ysim,X1,X2)
GLM_cov <- solve(Fisher_IM)
glm_std_error[M] <- sqrt(t(grad_glm)%*%GLM_cov%*%grad_glm)
# Find prediction CI and check if true_value falls within it
glm_con_int <- c(glm_pred[M] + qnorm(0.975)*glm_std_error[M],
glm_pred[M] - qnorm(0.975)*glm_std_error[M])
if (true_value <= max(glm_con_int) && true_value >=min(glm_con_int)){
glm_con_int_count[M,1] <- 1
}else{
glm_con_int_count[M,1] <- 0
}
# Find std deviation CI and check if true_sd falls within it
grad_glm_sd <- c(0, 0, 0,
-(1/2)*((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^(-3/2)),
-(1/2)*x_val*((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^(-3/2)),
-(1/2)*x_val^2*((beta2_new[1]+beta2_new[2]*x_val+beta2_new[3]*x_val^2)^(-3/2)))
Fisher_IM_sd <- -D2lik(beta1_new,beta2_new,Ysim,X1,X2)
GLM_cov_sd <- solve(Fisher_IM_sd)
glm_std_error_sd[M] <- sqrt(t(grad_glm_sd)%*%GLM_cov_sd%*%grad_glm_sd)
glm_con_int_sd <- c(glm_sd[M] + qnorm(0.975)*glm_std_error_sd[M],
glm_sd[M] - qnorm(0.975)*glm_std_error_sd[M])
if (true_sd <= max(glm_con_int_sd) && true_sd >=min(glm_con_int_sd)){
glm_con_int_count[M,2] <- 1
}else{
glm_con_int_count[M,2] <- 0
}
#-----------------------------------------------
# Fit and predict with the standard linear model
fit_lm <- lm(Ysim~x+x2)
lm_pred[M] <- fit_lm$coefficients[1] + fit_lm$coefficients[2]*x_val +
fit_lm$coefficients[3]*x_val^2
# Find standard deviation
lm_sd[M] <- sqrt(sum(fit_lm$residuals^2)/n)
# Find standard error for prediction
var_est_lm <- sum(fit_lm$residuals^2)/n # variance estimator
beta1_lm <- fit_full$coefficients/var_est
names(beta1_lm) <- c("beta10", "beta11", "beta12")
beta2_lm <- 1/var_est
names(beta2_lm) <- c("beta20")
X1 <- cbind(matrix(1,n,1),x,x^2)
X2_lm <- cbind(matrix(1,n,1))
grad_lm <- c(1/beta2_lm[1], x_val/beta2_lm[1], x_val^2/beta2_lm[1],
(-beta1_lm[1]-beta1_lm[2]*x_val-beta1_lm[3]*x_val^2)/beta2_lm[1]^2)
Fisher_IM <- -D2lik(beta1_lm,beta2_lm,Ysim,X1,X2_lm)
LM_cov <- solve(Fisher_IM)
lm_std_error[M] <- sqrt(t(grad_lm)%*%LM_cov%*%grad_lm)
lm_con_int <- c(lm_pred[M] + qnorm(0.975)*lm_std_error[M],
lm_pred[M] - qnorm(0.975)*lm_std_error[M])
if (true_value <= max(lm_con_int) && true_value >=min(lm_con_int)){
lm_con_int_count[M,1] <- 1
}else{
lm_con_int_count[M,1] <- 0
}
# Find std deviation CI and check if true_sd falls within it
grad_lm_sd <- c(0,0,0,-0.5*beta2_lm^(-3/2))
Fisher_IM_sd <- -D2lik(beta1_lm,beta2_lm,Ysim,X1,X2_lm)
LM_cov_sd <- solve(Fisher_IM_sd)
lm_std_error_sd[M] <- sqrt(t(grad_lm_sd)%*%LM_cov_sd%*%grad_lm_sd)
lm_con_int_sd <- c(lm_sd[M] + qnorm(0.975)*lm_std_error_sd[M],
lm_sd[M] - qnorm(0.975)*lm_std_error_sd[M])
if (true_sd <= max(lm_con_int_sd) && true_sd >=min(lm_con_int_sd)){
lm_con_int_count[M,2] <- 1
}else{
lm_con_int_count[M,2] <- 0
}
}
boxplot(glm_pred, lm_pred, names = c("GLM", "Standard linear model"), ylab="Predicted y")
abline(h = true_value, col="blue")
boxplot(glm_sd, lm_sd, names = c("GLM", "Standard linear model"), ylab="Standard deviation")
abline(h = true_sd, col="blue")
# Calculate percent of successes
(sum(glm_con_int_count[,1])/num_trial)*100
(sum(glm_con_int_count[,2])/num_trial)*100
(sum(lm_con_int_count[,1])/num_trial)*100
(sum(lm_con_int_count[,2])/num_trial)*100
55/.165
55/.13
# Calculate percent of successes
(sum(glm_con_int_count[,1])/num_trial)*100
(sum(glm_con_int_count[,2])/num_trial)*100
(sum(lm_con_int_count[,1])/num_trial)*100
(sum(lm_con_int_count[,2])/num_trial)*100
rm(list=ls())
f1 <- rexp(100, 1)
hist(f1)
f2 <- abs(rnorm(100,0,1))
hist(f2)
h <- 0.2
rm(list=ls())
f1_sample <- rexp(100, 1)
hist(f1_sample)
f2_sample <- abs(rnorm(100,0,1))
hist(f2_sample)
h <- 0.2
kernel <- function(z){
k <- 1/sqrt(2*pi)*exp(-z^2/2)
return(k)
}
f1_sample_all <- rbind(f1_sample, -f1_sample)
f2_sample_all <- rbind(f2_sample, -f2_sample)
for (i in 1:200){
kernel(f1_sample_all[i])
kernel(f2_sample_all[i])
}
f1_k <- matrix(0,200,0)
f2_k <- matrix(0,200,0)
for (i in 1:200){
f1_k[i] <- kernel(f1_sample_all[i])
f2_k[i] <- kernel(f2_sample_all[i])
}
sum(f1_k)
sum(f2_k)
setwd("~/Desktop/Metrum/PBPK_PC")
# This script reproduces manuscript figures
# Clear environment
rm(list=ls())
# Load libraries
.libPaths("lib")
library(dplyr)
library(ggplot2)
library(mrgsolve)
library(gridExtra)
library(PKNCA)
library(msm)
library(kableExtra)
setwd("~/Desktop/Metrum/PBPK_PC/script")
# This script reproduces manuscript figures
# Clear environment
rm(list=ls())
# Load libraries
.libPaths("lib")
library(dplyr)
library(ggplot2)
library(mrgsolve)
library(gridExtra)
library(PKNCA)
library(msm)
library(kableExtra)
source("CalcKp_P&T.R")
source("CalcKp_R&R.R")
source("CalcKpu_R&R.R")
source("CalcKp_Berez.R")
source("CalcKp_Schmitt.R")
source("CalcKp_pksim.R")
source("CalcVss_P&T.R")
source("getPartitionCoeff.R")
library(mrgsolve)
######################################### Voriconazole - weak base ###################################
# Reference:
# Compile model
mod <- mread("../model/voriPBPK_Adult")
remove.packages("mrgsolve")
install.packages('mrgsolve', dependencies = TRUE)
# This script reproduces manuscript figures
# Clear environment
rm(list=ls())
# Load libraries
.libPaths("lib")
library(dplyr)
library(ggplot2)
library(mrgsolve)
